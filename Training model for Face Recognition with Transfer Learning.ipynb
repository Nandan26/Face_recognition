{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16 #to import model from ImageNet we can any other model to if we want\n",
    "from keras.applications.vgg16 import preprocess_input #to import existing weights and all that\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# re-size all the images to this\n",
    "# because vgg16 accepts only size 224,224\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "#training path\n",
    "train_path = 'dataset/train'\n",
    "valid_path = 'dataset/test'\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "#here by adding +3 we add channel\n",
    "#include_top means we want to drop output of this pretrained model bcz it was trained for thousand of classification\n",
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# here weights are already assigned we don't want to retrain our model again\n",
    "for layer in vgg.layers:\n",
    "  layer.trainable = False\n",
    "  \n",
    "\n",
    "  \n",
    " # this function is useful for getting number of classes in train folder\n",
    "folders = glob('dataset/train/*')\n",
    "  \n",
    "\n",
    "# our layers - you can add more if you want, so here we are flattening output of vgg\n",
    "x = Flatten()(vgg.output)\n",
    "#using below code we are adding one more layer to our output\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "\n",
    "#here we are creating final layer which nodes are equals to number of folders\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# tell the model what cost and optimization method to use\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 30,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 30,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "'''r=model.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 5,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)'''\n",
    "\n",
    "# fit the model\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "# loss\n",
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the accuracy graph\n",
    "loss_train = r.history['acc']\n",
    "loss_val = r.history['val_acc']\n",
    "epochs = range(1,6)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training accuracy')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-extension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "model.save('facerecognition_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-intelligence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
